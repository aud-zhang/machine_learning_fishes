{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import walk, listdir\n",
    "import warnings\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in image data / preprocessing test with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "img_path = '/Users/shawn/Developer/ML-Research/training_img-sets/randall/Acanthuridae/Acanthurus_Acanthurus achilles_-117788879.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_data = image.img_to_array(img)\n",
    "img_data = np.expand_dims(img_data, axis=0)\n",
    "img_data = preprocess_input(img_data)\n",
    "\n",
    "vgg16_feature = model.predict(img_data)\n",
    "\n",
    "print(vgg16_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Image Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GetFishDirs Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain all subdirs of fish\n",
    "def getFishDirs(file_path):\n",
    "    randall_fish = [f.path for f in os.scandir(file_path) if f.is_dir()]\n",
    "    \n",
    "    return(randall_fish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Fish Paths per Subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "randall = '/Users/shawn/Developer/ML-Research/training_img-sets/randall/'\n",
    "fish_subdirs = getFishDirs(randall)\n",
    "\n",
    "fish_paths = []\n",
    "\n",
    "for i in range(len(fish_subdirs)):\n",
    "    for (dirpath, dirnames, filenames) in walk(fish_subdirs[i]):\n",
    "        for j in range(len(filenames)):\n",
    "            img = dirpath + '/' + filenames[j]\n",
    "            if \"Store\" not in img:\n",
    "                fish_paths.append(img)\n",
    "            \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "vgg16_feature_list = []\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Image Processing...\n",
      "99.98894905514422676\n",
      "Image Processing Completed!\n",
      "VGG16 Feature List and KMeans Computed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Beginning Image Processing...\")\n",
    "\n",
    "for i, fname in enumerate(fish_paths):\n",
    "    # process files under pre-fetched subdirs\n",
    "    img = image.load_img(fish_paths[i], target_size=(224, 224))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    \n",
    "    vgg16_feature = model.predict(img_data)\n",
    "    vgg16_feature_np = np.array(vgg16_feature)\n",
    "    vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "    \n",
    "    # progress percentage in console during img processing for tracking\n",
    "    sys.stdout.write(\"\\r{0}\".format((float(i)/len(fish_paths))*100))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "print(\"\\nImage Processing Completed!\")\n",
    "\n",
    "vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(vgg16_feature_list_np)\n",
    "\n",
    "print(\"VGG16 Feature List and KMeans Computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Cluster Validation Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Internal Cluster Validation Score: 0.032346845\n",
      "\n",
      "Predicted Clusters: [6 7 1 ... 4 7 7]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = kmeans.labels_\n",
    "\n",
    "ICV_Score = metrics.silhouette_score(vgg16_feature_list_np, predicted_labels, metric='euclidean')\n",
    "print(\"Internal Cluster Validation Score:\", ICV_Score)\n",
    "\n",
    "print(\"\\nPredicted Clusters:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define write_list_to_file (non-np array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(fishy_paths_list, filename):\n",
    "    # Write the list to CSV file\n",
    "\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for entries in fishy_paths_list:\n",
    "            outfile.write(entries)\n",
    "            outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Outputs to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_output_filename = \"pred_clusters_randallfish.csv\"\n",
    "fish_paths_output_filename = \"fish_paths_randallfish.csv\"\n",
    "concat_clusters_fishpaths_filename = \"fish_predictions_output.csv\"\n",
    "\n",
    "# save separate CSVs\n",
    "np.savetxt(cluster_output_filename, predicted_labels, delimiter=\",\")\n",
    "write_list_to_file(fish_paths, fish_paths_output_filename)\n",
    "\n",
    "# concatenate paths and cluster identification CSVs\n",
    "df1 = pd.read_csv(cluster_output_filename)\n",
    "df2 = pd.read_csv(fish_paths_output_filename)\n",
    "df3 = pd.concat([df2, df1], axis=1)\n",
    "df3.to_csv(concat_clusters_fishpaths_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

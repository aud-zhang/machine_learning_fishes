{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the waters\n",
    "\n",
    "Can ignore this section of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leannwoo/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            rescale=1./255,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('/Users/leannwoo/Dropbox/machine_learning_fishes/image_classifiers/Eyespots_all_species/eyespot/Apogon_Apogon cavitiensis_-1692469642.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                         save_to_dir='preview', save_prefix='eyespot', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our model\n",
    "\n",
    "Start paying attention here\n",
    "\n",
    "Solid explanation of kfold cross validation: https://www.openml.org/a/estimation-procedures/1  \n",
    "Code based on: https://www.kaggle.com/stefanie04736/simple-keras-model-with-k-fold-cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leannwoo/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('*.jpg')\n",
    "len(images)\n",
    "\n",
    "\n",
    "def getFish(filepath):\n",
    "    img = cv2.imread(filepath)\n",
    "    # standardize size for prediction step\n",
    "    img = cv2.resize(img, (150, 150))\n",
    "    img = img/255.0\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    \n",
    "    classification, _, species = filepath.partition('_')\n",
    "    \n",
    "    #res = model.predict(img)\n",
    "    return(img, classification, species)\n",
    "\n",
    "def load_data_kfold(k, image_filepaths):\n",
    "    \n",
    "    #use getFish function \n",
    "    #load in one file, append to a list\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for i in range(len(image_filepaths)):\n",
    "        x, y, _ = getFish(image_filepaths[i])\n",
    "        x_train.append(x)\n",
    "        y_train.append(y)\n",
    "        if (y_train[i] == 'eyespot'):\n",
    "            y_train[i] = 0\n",
    "        else:\n",
    "            y_train[i] = 1\n",
    "    \n",
    "#     train = pd.read_json('../input/train.json')\n",
    "#     train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "    \n",
    "#     x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "#     x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "#     x_band3 = x_band1 / x_band2\n",
    "       \n",
    "#     X_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "#                             , x_band2[:, :, :, np.newaxis]\n",
    "#                             , x_band3[:, :, :, np.newaxis]], axis=-1)\n",
    "                         \n",
    "#     y_train = np.array(train[\"is_iceberg\"])\n",
    "    \n",
    "    #StratifiedKFold can only work in binary; convert labels to categorical afterwards\n",
    "    folds = list(StratifiedKFold(n_splits=k, shuffle=True, random_state=1).split(x_train, y_train))\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    \n",
    "    return folds, x_train, y_train\n",
    "\n",
    "k = 10\n",
    "folds, x_train, y_train = load_data_kfold(k, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = '/Users/leannwoo/Dropbox/machine_learning_fishes/image_classifiers/Eyespots_all_species/'\n",
    "validation_data_dir = '/Users/leannwoo/Dropbox/machine_learning_fishes/image_classifiers/Eyespots_all_species_validation/'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 2\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT RUN THIS BLOCK IF USING KFOLD CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is the augmentation configuration we will use for training\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1. / 255,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True)\n",
    "\n",
    "# # this is the augmentation configuration we will use for testing:\n",
    "# # only rescaling\n",
    "# test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     train_data_dir,\n",
    "#     target_size=(img_width, img_height),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical')\n",
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#     validation_data_dir,\n",
    "#     target_size=(img_width, img_height),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical')\n",
    "\n",
    "# train_generator[1][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 849ms/step - loss: 0.2482 - acc: 0.5286 - val_loss: 0.2410 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.2278 - acc: 0.5781 - val_loss: 0.2687 - val_acc: 0.5000\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "[0.26872968673706055, 0.5]\n",
      "\n",
      "Fold  1\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.2570 - acc: 0.5964 - val_loss: 0.1955 - val_acc: 0.8750\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.2241 - acc: 0.6893 - val_loss: 0.2035 - val_acc: 0.5000\n",
      "8/8 [==============================] - 0s 14ms/step\n",
      "[0.20348475873470306, 0.5]\n",
      "\n",
      "Fold  2\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.2445 - acc: 0.5482 - val_loss: 0.2268 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.2329 - acc: 0.5804 - val_loss: 0.2294 - val_acc: 0.6250\n",
      "8/8 [==============================] - 0s 15ms/step\n",
      "[0.22943437099456787, 0.625]\n",
      "\n",
      "Fold  3\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.2308 - acc: 0.5804 - val_loss: 0.2579 - val_acc: 0.3750\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.2246 - acc: 0.6536 - val_loss: 0.2425 - val_acc: 0.6250\n",
      "8/8 [==============================] - 0s 14ms/step\n",
      "[0.242535799741745, 0.625]\n",
      "\n",
      "Fold  4\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.2540 - acc: 0.6000 - val_loss: 0.1938 - val_acc: 0.8750\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 778ms/step - loss: 0.2267 - acc: 0.6406 - val_loss: 0.1768 - val_acc: 0.8750\n",
      "8/8 [==============================] - 0s 14ms/step\n",
      "[0.17681437730789185, 0.875]\n",
      "\n",
      "Fold  5\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.2076 - acc: 0.7304 - val_loss: 0.2160 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.2278 - acc: 0.6089 - val_loss: 0.2125 - val_acc: 0.6250\n",
      "8/8 [==============================] - 0s 18ms/step\n",
      "[0.2124805748462677, 0.625]\n",
      "\n",
      "Fold  6\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.2425 - acc: 0.5518 - val_loss: 0.2581 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 808ms/step - loss: 0.2119 - acc: 0.6406 - val_loss: 0.2834 - val_acc: 0.5000\n",
      "8/8 [==============================] - 0s 18ms/step\n",
      "[0.2833672761917114, 0.5]\n",
      "\n",
      "Fold  7\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.2357 - acc: 0.5643 - val_loss: 0.1583 - val_acc: 0.8750\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 798ms/step - loss: 0.2381 - acc: 0.5469 - val_loss: 0.1507 - val_acc: 1.0000\n",
      "8/8 [==============================] - 0s 17ms/step\n",
      "[0.1507425308227539, 1.0]\n",
      "\n",
      "Fold  8\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.2156 - acc: 0.6571 - val_loss: 0.1973 - val_acc: 0.7500\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.1974 - acc: 0.7018 - val_loss: 0.2145 - val_acc: 0.6250\n",
      "8/8 [==============================] - 0s 14ms/step\n",
      "[0.21450823545455933, 0.625]\n",
      "\n",
      "Fold  9\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.2143 - acc: 0.6857 - val_loss: 0.1812 - val_acc: 0.7500\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.2145 - acc: 0.6446 - val_loss: 0.2638 - val_acc: 0.5000\n",
      "8/8 [==============================] - 0s 14ms/step\n",
      "[0.263836532831192, 0.5]\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.1,\n",
    "                         rotation_range = 10\n",
    "                        )\n",
    "\n",
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    X_train_cv = []\n",
    "    y_train_cv = []\n",
    "    X_valid_cv = []\n",
    "    y_valid_cv = []\n",
    "    \n",
    "    for i in range(len(train_idx)):\n",
    "        X_train_cv.append(x_train[train_idx[i]])\n",
    "        y_train_cv.append(y_train[train_idx[i]])\n",
    "    for i in range(len(val_idx)):\n",
    "        X_valid_cv.append(x_train[val_idx[i]])\n",
    "        y_valid_cv.append(y_train[val_idx[i]])\n",
    "    \n",
    "    X_train_cv = np.array(X_train_cv)\n",
    "    X_train_cv = np.squeeze(X_train_cv, axis = 1)\n",
    "    \n",
    "    X_valid_cv = np.array(X_valid_cv)\n",
    "    X_valid_cv = np.squeeze(X_valid_cv, axis = 1)\n",
    "    \n",
    "    y_train_cv = np.array(y_train_cv)\n",
    "    y_valid_cv = np.array(y_valid_cv)\n",
    "    \n",
    "    print '\\nFold ',j\n",
    "    name_weights = \"final_model_fold\" + str(j) + \"_weights.h5\"\n",
    "    generator = gen.flow(X_train_cv, y_train_cv, batch_size = batch_size)\n",
    "    model.fit_generator(\n",
    "                generator,\n",
    "                steps_per_epoch=len(X_train_cv)/batch_size,\n",
    "                epochs=2,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data = (X_valid_cv, y_valid_cv))\n",
    "    model.save_weights('first_try.h5')\n",
    "    model.save('second_try.h5')\n",
    "    print(model.evaluate(X_valid_cv, y_valid_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT RUN THIS BLOCK IF USING KFOLD CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=nb_train_samples // batch_size,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "# model.save_weights('first_try.h5')\n",
    "# model.save('second_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload model and use it to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def getFish(filepath):\n",
    "    img = cv2.imread(filepath)\n",
    "    # standardize size for prediction step\n",
    "    img = cv2.resize(img, (150, 150))\n",
    "    img = img/255.0\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    \n",
    "    classification, _, species = filepath.partition('_')\n",
    "    \n",
    "    #res = model.predict(img)\n",
    "    return(img, classification, species)\n",
    "\n",
    "#run through all images, classify,\n",
    "#and write out the classification category, \n",
    "#the confidence/weight of the prediction, \n",
    "#the species name, and the family. \n",
    "\n",
    "def predict(model, img):\n",
    "    prediction_weights = model.predict(img[0])\n",
    "    prediction = model.predict_classes(img[0])\n",
    "    if (prediction[0] == 0):\n",
    "        prediction = \"eyespot\"\n",
    "    else:\n",
    "        prediction = \"noeyespot\"\n",
    "    fam = img[2]\n",
    "    correct_class = img[1]\n",
    "    #print \"Model classification:\",prediction,\"\\nCorrect classification:\", correct_class,\"\\nPrediction wieghts:\",prediction_weights,\"\\nType:\",fam,\"\\n\"\n",
    "    return(prediction, correct_class, prediction_weights, fam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('eyespot',\n",
       " 'eyespot',\n",
       " array([[1.000000e+00, 5.364594e-38]], dtype=float32),\n",
       " 'Abudefduf_Abudefduf sparoides_929157376.jpg')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "mod = load_model(\"second_try.h5\")\n",
    "\n",
    "eyepath = \"eyespot_Abudefduf_Abudefduf sparoides_929157376.jpg\"\n",
    "noeyepath = \"noeyespot_Abudefduf_Abudefduf bengalensis_880932306.jpg\"\n",
    "\n",
    "predict(mod, getFish(eyepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "images = glob.glob('*.jpg')\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('classification_data.csv', 'wb') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    filewriter.writerow(['Model Classification', 'Correct Classification', 'Prediction Weights', 'Type'])\n",
    "\n",
    "    true_eye=0\n",
    "    true_noeye=0\n",
    "    false_eye=0\n",
    "    false_noeye=0\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        info = predict(mod, getFish(images[i]))\n",
    "        filewriter.writerow([info[0], info[1], info[2], info[3]])\n",
    "\n",
    "        #computing info for confusion matrix\n",
    "        if (info[0] == info[1]):\n",
    "            if (info[0] == 'eyespot'):\n",
    "                true_eye += 1\n",
    "            else:\n",
    "                true_noeye += 1\n",
    "        else:\n",
    "            if (info[0] == 'eyespot'):\n",
    "                false_eye += 1\n",
    "            else:\n",
    "                false_noeye += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eyespots</th>\n",
       "      <th>No Eyespots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eyespots (Model Output)</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Eyespots (Model Output)</th>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Eyespots  No Eyespots\n",
       "Eyespots (Model Output)           30            4\n",
       "No Eyespots (Model Output)        10           36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Eyespots':[true_eye, false_noeye], 'No Eyespots':[false_eye, true_noeye] }\n",
    "confusion_matrix = pd.DataFrame(data = data)\n",
    "confusion_matrix = confusion_matrix.rename({0:'Eyespots (Model Output)', 1:'No Eyespots (Model Output)'},axis='index')\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

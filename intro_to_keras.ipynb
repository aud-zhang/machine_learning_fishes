{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leannwoo/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            rescale=1./255,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('/Users/leannwoo/Dropbox/machine_learning_fishes/image_classifiers/Eyespots_all_species/eyespot/Apogon_Apogon cavitiensis_-1692469642.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                         save_to_dir='preview', save_prefix='eyespot', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leannwoo/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = '/Users/leannwoo/Dropbox/machine_learning_fishes/image_classifiers/Eyespots_all_species/'\n",
    "validation_data_dir = '/Users/leannwoo/Dropbox/machine_learning_fishes/image_classifiers/Eyespots_all_species_validation/'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 2\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "train_generator[1][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "125/125 [==============================] - 112s 898ms/step - loss: 0.7092 - acc: 0.6025 - val_loss: 1.0261 - val_acc: 0.3000\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - 109s 873ms/step - loss: 0.4438 - acc: 0.8010 - val_loss: 3.2146 - val_acc: 0.2000\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')\n",
    "model.save('second_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload model and use it to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def getFish(filepath):\n",
    "    img = cv2.imread(filepath)\n",
    "    # standardize size for prediction step\n",
    "    img = cv2.resize(img, (150, 150))\n",
    "    img = img/255.0\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    \n",
    "    classification, _, species = filepath.partition('_')\n",
    "    \n",
    "    #res = model.predict(img)\n",
    "    return(img, classification, species)\n",
    "\n",
    "#run through all images, classify,\n",
    "#and write out the classification category, \n",
    "#the confidence/weight of the prediction, \n",
    "#the species name, and the family. \n",
    "\n",
    "def predict(model, img):\n",
    "    prediction_weights = model.predict(img[0])\n",
    "    prediction = model.predict_classes(img[0])\n",
    "    if (prediction[0] == 0):\n",
    "        prediction = \"eyespot\"\n",
    "    else:\n",
    "        prediction = \"noeyespot\"\n",
    "    fam = img[2]\n",
    "    correct_class = img[1]\n",
    "    #print \"Model classification:\",prediction,\"\\nCorrect classification:\", correct_class,\"\\nPrediction wieghts:\",prediction_weights,\"\\nType:\",fam,\"\\n\"\n",
    "    return(prediction, correct_class, prediction_weights, fam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classification: eyespot \n",
      "Correct classification: eyespot \n",
      "Prediction wieghts: [[4.43086058e-01 1.03738705e-04]] \n",
      "Type: Abudefduf_Abudefduf sparoides_929157376.jpg \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('eyespot',\n",
       " 'eyespot',\n",
       " array([[4.43086058e-01, 1.03738705e-04]], dtype=float32),\n",
       " 'Abudefduf_Abudefduf sparoides_929157376.jpg')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "mod = load_model(\"second_try.h5\")\n",
    "\n",
    "eyepath = \"eyespot_Abudefduf_Abudefduf sparoides_929157376.jpg\"\n",
    "noeyepath = \"noeyespot_Abudefduf_Abudefduf bengalensis_880932306.jpg\"\n",
    "\n",
    "predict(mod, getFish(eyepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "images = glob.glob('*.jpg')\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('classification_data.csv', 'wb') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    filewriter.writerow(['Model Classification', 'Correct Classification', 'Prediction Weights', 'Type'])\n",
    "\n",
    "    true_eye=0\n",
    "    true_noeye=0\n",
    "    false_eye=0\n",
    "    false_noeye=0\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        info = predict(mod, getFish(images[i]))\n",
    "        filewriter.writerow([info[0], info[1], info[2], info[3]])\n",
    "\n",
    "        #computing info for confusion matrix\n",
    "        if (info[0] == info[1]):\n",
    "            if (info[0] == 'eyespot'):\n",
    "                true_eye += 1\n",
    "            else:\n",
    "                true_noeye += 1\n",
    "        else:\n",
    "            if (info[0] == 'eyespot'):\n",
    "                false_eye += 1\n",
    "            else:\n",
    "                false_noeye += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eyespots</th>\n",
       "      <th>No Eyespots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eyespots (Model Output)</th>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Eyespots (Model Output)</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Eyespots  No Eyespots\n",
       "Eyespots (Model Output)           37           13\n",
       "No Eyespots (Model Output)         3           27"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Eyespots':[true_eye, false_noeye], 'No Eyespots':[false_eye, true_noeye] }\n",
    "confusion_matrix = pd.DataFrame(data = data)\n",
    "confusion_matrix = confusion_matrix.rename({0:'Eyespots (Model Output)', 1:'No Eyespots (Model Output)'},axis='index')\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
